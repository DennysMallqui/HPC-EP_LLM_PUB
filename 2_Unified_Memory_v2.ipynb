{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lwd2WpaeMZW"
      },
      "source": [
        "<h1><div align=\"center\">Managing Accelerated Application Memory with CUDA C/C++ Unified Memory</div></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqtm6PdSeMZY"
      },
      "source": [
        "![CUDA](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/pictures/2019/NVIDIACuda_Logo.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-eui_rveMZZ"
      },
      "source": [
        "The [*CUDA Best Practices Guide*](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations), a highly recommended followup to this and other CUDA fundamentals labs, recommends a design cycle called **APOD**: **A**ssess, **P**arallelize, **O**ptimize, **D**eploy. In short, APOD prescribes an iterative design process, where developers can apply incremental improvements to their accelerated application's performance, and ship their code. As developers become more competent CUDA programmers, more advanced optimization techniques can be applied to their accelerated code bases.\n",
        "\n",
        "This lab will support such a style of iterative development. You will be using the Nsight Systems command line tool **nsys** to qualitatively measure your application's performance, and to identify opportunities for optimization, after which you will apply incremental improvements before learning new techniques and repeating the cycle. As a point of focus, many of the techniques you will be learning and applying in this lab will deal with the specifics of how CUDA's **Unified Memory** works. Understanding Unified Memory behavior is a fundamental skill for CUDA developers, and serves as a prerequisite to many more advanced memory management techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY6CBwCieMZZ"
      },
      "source": [
        "---\n",
        "## Prerequisites\n",
        "\n",
        "To get the most out of this lab you should already be able to:\n",
        "\n",
        "- Write, compile, and run C/C++ programs that both call CPU functions and launch GPU kernels.\n",
        "- Control parallel thread hierarchy using execution configuration.\n",
        "- Refactor serial loops to execute their iterations in parallel on a GPU.\n",
        "- Allocate and free Unified Memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_O6WEKVeMZa"
      },
      "source": [
        "---\n",
        "## Objectives\n",
        "\n",
        "By the time you complete this lab, you will be able to:\n",
        "\n",
        "- Use the Nsight Systems command line tool (**nsys**) to profile accelerated application performance.\n",
        "- Leverage an understanding of **Streaming Multiprocessors** to optimize execution configurations.\n",
        "- Understand the behavior of **Unified Memory** with regard to page faulting and data migrations.\n",
        "- Use **asynchronous memory prefetching** to reduce page faults and data migrations for increased performance.\n",
        "- Employ an iterative development cycle to rapidly accelerate and deploy applications."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEGYA3jimPtJ",
        "outputId": "bd98a68f-be9b-4baa-959d-812f09bf84d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  8 20:22:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSrFCfgveMZa"
      },
      "source": [
        "---\n",
        "## Iterative Optimizations with the NVIDIA Command Line Profiler\n",
        "\n",
        "The only way to be assured that attempts at optimizing accelerated code bases are actually successful is to profile the application for quantitative information about the application's performance. `nsys` is the Nsight Systems command line tool. It ships with the CUDA toolkit, and is a powerful tool for profiling accelerated applications.\n",
        "\n",
        "`nsys` is easy to use. Its most basic usage is to simply pass it the path to an executable compiled with `nvcc`. `nsys` will proceed to execute the application, after which it will print a summary output of the application's GPU activities, CUDA API calls, as well as information about **Unified Memory** activity, a topic which will be covered extensively later in this lab.\n",
        "\n",
        "When accelerating applications, or optimizing already-accelerated applications, take a scientific and iterative approach. Profile your application after making changes, take note, and record the implications of any refactoring on performance. Make these observations early and often: frequently, enough performance boost can be gained with little effort such that you can ship your accelerated application. Additionally, frequent profiling will teach you how specific changes to your CUDA code bases impact its actual performance: knowledge that is hard to acquire when only profiling after many kinds of changes in your code bases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjUiLT99eMZa"
      },
      "source": [
        "### Exercise: Profile an Application with nsys\n",
        "\n",
        "[01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) (<------ you can click on this and any of the source file links in this lab to open them for editing) is a naively accelerated vector addition program. Use the two code execution cells below (`CTRL` + `ENTER`). The first code execution cell will compile (and run) the vector addition program. The second code execution cell will profile the executable that was just compiled using `nsys profile`.\n",
        "\n",
        "`nsys profile` will generate a `qdrep` report file which can be used in a variety of manners. We use the `--stats=true` flag here to indicate we would like summary statistics printed. There is quite a lot of information printed:\n",
        "\n",
        "- Profile configuration details\n",
        "- Report file(s) generation details\n",
        "- **CUDA API Statistics**\n",
        "- **CUDA Kernel Statistics**\n",
        "- **CUDA Memory Operation Statistics (time and size)**\n",
        "- OS Runtime API Statistics\n",
        "\n",
        "In this lab you will primarily be using the 3 sections in **bold** above. In the next lab, you will be using the generated report files to give to the Nsight Systems GUI for visual profiling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94k4rkUoeMZb"
      },
      "source": [
        "After profiling the application, answer the following questions using information displayed in the `CUDA Kernel Statistics` section of the profiling output:\n",
        "\n",
        "- What was the name of the only CUDA kernel called in this application?\n",
        "- How many times did this kernel run?\n",
        "- How long did it take this kernel to run? Record this time somewhere: you will be optimizing this application and will want to know how much faster you can make it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir 01-vector-add"
      ],
      "metadata": {
        "id": "S_6M6aoXgYGt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<20;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  checkCuda( cudaMallocManaged(&a, size) );\n",
        "  checkCuda( cudaMallocManaged(&b, size) );\n",
        "  checkCuda( cudaMallocManaged(&c, size) );\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  threadsPerBlock = 256;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "//  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "  addVectorsInto<<<1, 1>>>(c, a, b, N);\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  checkCuda( cudaFree(a) );\n",
        "  checkCuda( cudaFree(b) );\n",
        "  checkCuda( cudaFree(c) );\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0v_UUG2iIaU",
        "outputId": "1babaf90-92a1-4c85-9b72-34ab0ca0e4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVf337WaeMZb",
        "outputId": "b48df014-3935-46ed-e7ae-5977dde16a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m01-vector-add/01-vector-add.cu(64)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"numberOfBlocks\"\u001b[0m was set but never used\n",
            "    size_t numberOfBlocks;\n",
            "           ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvcc  -arch=sm_75 -o single-thread-vector-add 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install nsight-systems-2023.3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNxReDI7ny2q",
        "outputId": "76c3d194-50ed-4ae9-f162-53d76d119a76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0\n",
            "  libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0\n",
            "  libxtst6\n",
            "The following NEW packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0\n",
            "  libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0\n",
            "  libxtst6 nsight-systems-2023.3.3\n",
            "0 upgraded, 12 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 325 MB of archives.\n",
            "After this operation, 1,269 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2023.3.3 2023.3.3.42-233333266658v0 [324 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Fetched 325 MB in 7s (47.6 MB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../01-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../02-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../03-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../04-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../05-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../06-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../07-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../08-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../09-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../10-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package nsight-systems-2023.3.3.\n",
            "Preparing to unpack .../11-nsight-systems-2023.3.3_2023.3.3.42-233333266658v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2023.3.3 (2023.3.3.42-233333266658v0) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up nsight-systems-2023.3.3 (2023.3.3.42-233333266658v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.3.3/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.3.3/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLO5I-_ReMZc",
        "outputId": "3014613c-dccc-44af-b227-e56939fda604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating '/tmp/nsys-report-bf17.qdstrm'\n",
            "[1/8] [========================100%] report1.nsys-rep\n",
            "[2/8] [========================100%] report1.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     91.6      870,969,999         39  22,332,564.1  10,075,989.0     1,952  321,620,576  53,704,903.6  poll                  \n",
            "      7.1       67,583,143        546     123,778.7      11,382.5       420   19,512,397   1,060,340.4  ioctl                 \n",
            "      0.8        7,573,163          2   3,786,581.5   3,786,581.5     2,323    7,570,840   5,351,749.7  pthread_cond_broadcast\n",
            "      0.2        1,792,859         31      57,834.2      13,693.0     8,357    1,064,573     187,788.1  mmap64                \n",
            "      0.1        1,339,369         22      60,880.4      10,001.0     2,593      432,701     125,451.7  mmap                  \n",
            "      0.0          462,439         10      46,243.9      53,797.0    12,059       74,561      21,507.3  sem_timedwait         \n",
            "      0.0          388,154         49       7,921.5       7,643.0     2,594       15,095       2,705.3  open64                \n",
            "      0.0          238,298         40       5,957.5       3,449.0     1,107       30,570       6,409.4  fopen                 \n",
            "      0.0          121,672          2      60,836.0      60,836.0    51,854       69,818      12,702.5  pthread_create        \n",
            "      0.0          100,084          1     100,084.0     100,084.0   100,084      100,084           0.0  pthread_cond_wait     \n",
            "      0.0           82,940          7      11,848.6       7,929.0     5,592       38,398      11,754.5  munmap                \n",
            "      0.0           62,875         33       1,905.3       1,347.0       936        7,637       1,452.8  fclose                \n",
            "      0.0           59,124         12       4,927.0       5,531.0     1,446        8,338       2,198.6  write                 \n",
            "      0.0           37,173         19       1,956.5          46.0        45       36,267       8,308.7  fgets                 \n",
            "      0.0           35,163          6       5,860.5       5,881.5     1,651       10,285       3,406.4  open                  \n",
            "      0.0           34,870         64         544.8         517.0       198        1,846         250.6  fcntl                 \n",
            "      0.0           23,180         15       1,545.3       1,424.0       607        3,355         809.4  read                  \n",
            "      0.0           20,775          3       6,925.0       6,870.0     4,235        9,670       2,717.9  pipe2                 \n",
            "      0.0           20,350          2      10,175.0      10,175.0     6,726       13,624       4,877.6  socket                \n",
            "      0.0           10,420          1      10,420.0      10,420.0    10,420       10,420           0.0  connect               \n",
            "      0.0            6,922          2       3,461.0       3,461.0     3,213        3,709         350.7  fwrite                \n",
            "      0.0            3,010          8         376.3         376.5       321          440          36.8  dup                   \n",
            "      0.0            1,581          1       1,581.0       1,581.0     1,581        1,581           0.0  bind                  \n",
            "      0.0              960          1         960.0         960.0       960          960           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  ----------------------\n",
            "     65.8      222,848,938          1  222,848,938.0  222,848,938.0  222,848,938  222,848,938           0.0  cudaDeviceSynchronize \n",
            "     33.8      114,384,043          3   38,128,014.3       54,214.0       19,760  114,310,069  65,975,596.9  cudaMallocManaged     \n",
            "      0.4        1,402,949          3      467,649.7      490,099.0      356,229      556,621     102,064.8  cudaFree              \n",
            "      0.1          186,281          1      186,281.0      186,281.0      186,281      186,281           0.0  cudaLaunchKernel      \n",
            "      0.0            1,276          1        1,276.0        1,276.0        1,276        1,276           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ----------------------------------------------\n",
            "    100.0      222,832,232          1  222,832,232.0  222,832,232.0  222,832,232  222,832,232          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "     77.4        2,431,297    144  16,884.0   5,455.0     2,943    87,166     24,299.7  [CUDA memcpy Unified Host-to-Device]\n",
            "     22.6          711,257     48  14,817.9   4,015.5     1,695    80,702     23,031.7  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "     25.166    144     0.175     0.033     0.004     1.044        0.302  [CUDA memcpy Unified Host-to-Device]\n",
            "      8.389     48     0.175     0.033     0.004     1.044        0.304  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report1.nsys-rep\n",
            "    /content/report1.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./single-thread-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLpcdWSAeMZd"
      },
      "source": [
        "Worth mentioning is that by default, `nsys profile` will not overwrite an existing report file. This is done to prevent accidental loss of work when profiling. If for any reason, you would rather overwrite an existing report file, say during rapid iterations, you can provide the `-f` flag to `nsys profile` to allow overwriting an existing report file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ah-EEWGeMZd"
      },
      "source": [
        "### Exercise: Optimize and Profile\n",
        "\n",
        "Take a minute or two to make a simple optimization to [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) by updating its execution configuration so that it runs on many threads in a single thread block. Recompile and then profile with `nsys profile --stats=true` using the code execution cells below. Use the profiling output to check the runtime of the kernel. What was the speed up from this optimization? Be sure to record your results somewhere."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  checkCuda( cudaMallocManaged(&a, size) );\n",
        "  checkCuda( cudaMallocManaged(&b, size) );\n",
        "  checkCuda( cudaMallocManaged(&c, size) );\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  threadsPerBlock = 256;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  checkCuda( cudaFree(a) );\n",
        "  checkCuda( cudaFree(b) );\n",
        "  checkCuda( cudaFree(c) );\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3YMToSDnu0l",
        "outputId": "a084c174-327a-4458-a413-0323c4ac7e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPZUsPXQeMZd"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o multi-thread-vector-add 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /tmp/nsys*\n",
        "!ls -l /tmp/nsys*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jblciw7MoMFd",
        "outputId": "9f91151c-4e8b-40a8-e409-ada3dc6240ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/tmp/nsys*': No such file or directory\n",
            "ls: cannot access '/tmp/nsys*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdycjJkmeMZd",
        "outputId": "62f80910-d67a-4500-c0fc-f6f376ed84e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating '/tmp/nsys-report-f70c.qdstrm'\n",
            "[1/8] [========================100%] report3.nsys-rep\n",
            "[2/8] [========================100%] report3.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report3.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     90.2    1,647,478,770         73  22,568,202.3  10,073,465.0     1,531  318,527,692  44,527,288.5  poll                  \n",
            "      8.1      147,212,413        546     269,619.8      11,225.0       399  105,834,635   4,546,439.6  ioctl                 \n",
            "      1.2       21,705,915         24     904,413.1      11,171.5     2,598    8,673,188   2,437,856.5  mmap                  \n",
            "      0.4        6,951,208          2   3,475,604.0   3,475,604.0     2,045    6,949,163   4,912,354.2  pthread_cond_broadcast\n",
            "      0.1        1,731,028         31      55,839.6      13,199.0     9,450    1,066,600     188,250.8  mmap64                \n",
            "      0.0          525,920         10      52,592.0      56,080.5    20,377       90,927      19,079.4  sem_timedwait         \n",
            "      0.0          372,752         49       7,607.2       7,258.0     2,600       14,294       2,361.4  open64                \n",
            "      0.0          217,480         40       5,437.0       3,339.5     1,112       23,054       5,078.2  fopen                 \n",
            "      0.0          107,888          2      53,944.0      53,944.0    46,956       60,932       9,882.5  pthread_create        \n",
            "      0.0          105,587         11       9,598.8       7,237.0     4,204       22,084       5,375.6  munmap                \n",
            "      0.0           93,437          1      93,437.0      93,437.0    93,437       93,437           0.0  pthread_cond_wait     \n",
            "      0.0           63,330         12       5,277.5       5,941.5     1,614        7,902       2,175.5  write                 \n",
            "      0.0           58,783         33       1,781.3       1,290.0       864        5,554       1,140.3  fclose                \n",
            "      0.0           37,142         19       1,954.8          46.0        45       36,228       8,299.6  fgets                 \n",
            "      0.0           34,274         64         535.5         555.0       179        1,060         175.1  fcntl                 \n",
            "      0.0           32,768          6       5,461.3       4,697.5     2,151       10,019       3,030.7  open                  \n",
            "      0.0           21,535         15       1,435.7       1,279.0       725        2,892         575.0  read                  \n",
            "      0.0           19,286          2       9,643.0       9,643.0     7,624       11,662       2,855.3  socket                \n",
            "      0.0           18,747          3       6,249.0       6,574.0     4,478        7,695       1,632.9  pipe2                 \n",
            "      0.0           10,519          1      10,519.0      10,519.0    10,519       10,519           0.0  connect               \n",
            "      0.0            6,760          2       3,380.0       3,380.0     3,359        3,401          29.7  fwrite                \n",
            "      0.0            2,683          8         335.4         333.0       312          360          13.8  dup                   \n",
            "      0.0            1,428          1       1,428.0       1,428.0     1,428        1,428           0.0  bind                  \n",
            "      0.0              857          1         857.0         857.0       857          857           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -------------  ----------------------\n",
            "     59.8      193,567,097          3   64,522,365.7       73,739.0       38,803  193,454,555  111,658,552.7  cudaMallocManaged     \n",
            "     33.5      108,368,276          1  108,368,276.0  108,368,276.0  108,368,276  108,368,276            0.0  cudaDeviceSynchronize \n",
            "      6.7       21,646,530          3    7,215,510.0    6,595,790.0    6,326,682    8,724,058    1,313,351.7  cudaFree              \n",
            "      0.1          197,125          1      197,125.0      197,125.0      197,125      197,125            0.0  cudaLaunchKernel      \n",
            "      0.0              965          1          965.0          965.0          965          965            0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ----------------------------------------------\n",
            "    100.0      108,352,162          1  108,352,162.0  108,352,162.0  108,352,162  108,352,162          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "     80.1       46,815,536  5,083   9,210.2   3,775.0     2,463    84,671     16,465.2  [CUDA memcpy Unified Host-to-Device]\n",
            "     19.9       11,610,231    768  15,117.5   4,415.5     2,014    81,215     22,811.2  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    402.653  5,083     0.079     0.012     0.004     1.016        0.204  [CUDA memcpy Unified Host-to-Device]\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report3.nsys-rep\n",
            "    /content/report3.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./multi-thread-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9edc8HZkeMZe"
      },
      "source": [
        "### Exercise: Optimize Iteratively\n",
        "\n",
        "In this exercise you will go through several cycles of editing the execution configuration of [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu), profiling it, and recording the results to see the impact. Use the following guidelines while working:\n",
        "\n",
        "- Start by listing 3 to 5 different ways you will update the execution configuration, being sure to cover a range of different grid and block size combinations.\n",
        "- Edit the [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) program in one of the ways you listed.\n",
        "- Compile and profile your updated code with the two code execution cells below.\n",
        "- Record the runtime of the kernel execution, as given in the profiling output.\n",
        "- Repeat the edit/profile/record cycle for each possible optimization you listed above\n",
        "\n",
        "Which of the execution configurations you attempted proved to be the fastest?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<20;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  // Punteros Host (CPU)\n",
        "  float *h_a, *h_b, *h_c;\n",
        "  // Punteros Device (GPU)\n",
        "  float *d_a, *d_b, *d_c;\n",
        "\n",
        "  // CPU\n",
        "  h_a = (float*)malloc(size);\n",
        "  h_b = (float*)malloc(size);\n",
        "  h_c = (float*)malloc(size);\n",
        "\n",
        "  // GPU\n",
        "  checkCuda( cudaMalloc(&d_a, size) );\n",
        "  checkCuda( cudaMalloc(&d_b, size) );\n",
        "  checkCuda( cudaMalloc(&d_c, size) );\n",
        "\n",
        "  initWith(3, h_a, N);\n",
        "  initWith(4, h_b, N);\n",
        "  initWith(0, h_c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  threadsPerBlock = 256;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "  checkCuda( cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice) );\n",
        "  checkCuda( cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice) );\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(d_c, d_a, d_b, N);\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "\n",
        "  checkCuda( cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, h_c, N);\n",
        "\n",
        "  checkCuda( cudaFree(d_a) );\n",
        "  checkCuda( cudaFree(d_b) );\n",
        "  checkCuda( cudaFree(d_c) );\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEUdkCIKRu6M",
        "outputId": "e9a7f44c-5955-4410-f8e7-00907cf95c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVZvRd2eeMZe"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o iteratively-optimized-vector-add 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvtbVkeeMZe",
        "outputId": "f7b1b0bc-702b-4c71-e121-ce7dfb547310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating '/tmp/nsys-report-51eb.qdstrm'\n",
            "[1/8] [========================100%] report5.nsys-rep\n",
            "[2/8] [========================100%] report5.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report5.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -----------  --------  -----------  ------------  ----------------------\n",
            "     84.5      430,651,093         13  33,127,007.2  2,518,574.0     2,044  330,102,517  90,252,719.1  poll                  \n",
            "     13.8       70,461,851        543     129,764.0     13,720.0       389   19,837,162   1,045,873.3  ioctl                 \n",
            "      0.9        4,652,686          2   2,326,343.0  2,326,343.0     3,877    4,648,809   3,284,462.9  pthread_cond_broadcast\n",
            "      0.4        1,857,789         31      59,928.7     14,888.0     9,645    1,131,283     199,621.9  mmap64                \n",
            "      0.1          463,150          7      66,164.3     68,749.0    48,738       85,097      15,844.9  sem_timedwait         \n",
            "      0.1          415,574         49       8,481.1      7,554.0     3,617       16,069       2,494.9  open64                \n",
            "      0.1          279,473         40       6,986.8      4,863.5     1,630       31,679       6,212.0  fopen                 \n",
            "      0.0          213,552         16      13,347.0      8,370.0     3,823       60,662      14,272.1  mmap                  \n",
            "      0.0          134,625          2      67,312.5     67,312.5    64,636       69,989       3,785.1  pthread_create        \n",
            "      0.0          105,105          1     105,105.0    105,105.0   105,105      105,105           0.0  pthread_cond_wait     \n",
            "      0.0           99,515         12       8,292.9      7,686.5     1,143       15,135       3,807.2  write                 \n",
            "      0.0           78,180         33       2,369.1      2,107.0     1,575        7,718       1,181.6  fclose                \n",
            "      0.0           75,951          7      10,850.1     10,437.0     7,253       17,996       3,451.1  munmap                \n",
            "      0.0           50,954         19       2,681.8         71.0        53       49,628      11,368.6  fgets                 \n",
            "      0.0           42,881          6       7,146.8      7,258.5     2,881       10,993       2,794.2  open                  \n",
            "      0.0           37,226         64         581.7        566.0       200        1,288         215.0  fcntl                 \n",
            "      0.0           24,272         15       1,618.1      1,403.0       441        3,705         927.0  read                  \n",
            "      0.0           21,191          3       7,063.7      6,946.0     5,001        9,244       2,123.9  pipe2                 \n",
            "      0.0           20,975          2      10,487.5     10,487.5     8,646       12,329       2,604.3  socket                \n",
            "      0.0           10,938          1      10,938.0     10,938.0    10,938       10,938           0.0  connect               \n",
            "      0.0            7,562          2       3,781.0      3,781.0     3,026        4,536       1,067.7  fwrite                \n",
            "      0.0            3,021          8         377.6        357.0       313          452          53.9  dup                   \n",
            "      0.0            2,310          1       2,310.0      2,310.0     2,310        2,310           0.0  bind                  \n",
            "      0.0            1,427          1       1,427.0      1,427.0     1,427        1,427           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)    Max (ns)   StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -----------  ---------  ----------  ------------  ----------------------\n",
            "     93.5       95,312,807          3  31,770,935.7    127,885.0     86,998  95,097,924  54,842,784.5  cudaMalloc            \n",
            "      5.4        5,507,209          3   1,835,736.3  1,833,547.0  1,824,077   1,849,585      12,894.2  cudaMemcpy            \n",
            "      0.9          957,647          3     319,215.7    380,871.0    169,652     407,124     130,189.4  cudaFree              \n",
            "      0.2          172,613          1     172,613.0    172,613.0    172,613     172,613           0.0  cudaLaunchKernel      \n",
            "      0.0            6,586          1       6,586.0      6,586.0      6,586       6,586           0.0  cudaDeviceSynchronize \n",
            "      0.0            1,470          1       1,470.0      1,470.0      1,470       1,470           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------\n",
            "    100.0          110,014          1  110,014.0  110,014.0   110,014   110,014          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)           Operation          \n",
            " --------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ----------------------------\n",
            "     69.7        3,257,308      2  1,628,654.0  1,628,654.0  1,626,526  1,630,782      3,009.4  [CUDA memcpy Host-to-Device]\n",
            "     30.3        1,416,002      1  1,416,002.0  1,416,002.0  1,416,002  1,416,002          0.0  [CUDA memcpy Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
            "     16.777      2     8.389     8.389     8.389     8.389        0.000  [CUDA memcpy Host-to-Device]\n",
            "      8.389      1     8.389     8.389     8.389     8.389        0.000  [CUDA memcpy Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report5.nsys-rep\n",
            "    /content/report5.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./iteratively-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWGTzUDreMZe"
      },
      "source": [
        "---\n",
        "## Streaming Multiprocessors and Querying the Device\n",
        "\n",
        "This section explores how understanding a specific feature of the GPU hardware can promote optimization. After introducing **Streaming Multiprocessors**, you will attempt to further optimize the accelerated vector addition program you have been working on.\n",
        "\n",
        "The following slides present upcoming material visually, at a high level. Click through the slides before moving on to more detailed coverage of their topics in following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "ab0hHVRmeMZe",
        "outputId": "9f534b72-afb5-4637-d442-0d1d64efc24c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task2/NVPROF_UM_1.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%HTML\n",
        "\n",
        "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task2/NVPROF_UM_1.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnMkJWc6eMZf"
      },
      "source": [
        "### Streaming Multiprocessors and Warps\n",
        "\n",
        "The GPUs that CUDA applications run on have processing units called **streaming multiprocessors**, or **SMs**. During kernel execution, blocks of threads are given to SMs to execute. In order to support the GPU's ability to perform as many parallel operations as possible, performance gains can often be had by *choosing a grid size that has a number of blocks that is a multiple of the number of SMs on a given GPU.*\n",
        "\n",
        "Additionally, SMs create, manage, schedule, and execute groupings of 32 threads from within a block called **warps**. A more [in depth coverage of SMs and warps](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation) is beyond the scope of this course, however, it is important to know that performance gains can also be had by *choosing a block size that has a number of threads that is a multiple of 32.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUHPkXFUeMZf"
      },
      "source": [
        "### Programmatically Querying GPU Device Properties\n",
        "\n",
        "In order to support portability, since the number of SMs on a GPU can differ depending on the specific GPU being used, the number of SMs should not be hard-coded into a code bases. Rather, this information should be acquired programatically.\n",
        "\n",
        "The following shows how, in CUDA C/C++, to obtain a C struct which contains many properties about the currently active GPU device, including its number of SMs:\n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                  // `deviceId` now points to the id of the currently active GPU.\n",
        "\n",
        "cudaDeviceProp props;\n",
        "cudaGetDeviceProperties(&props, deviceId); // `props` now has many useful properties about\n",
        "                                           // the active GPU device.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_hAIg0KeMZf"
      },
      "source": [
        "### Exercise: Query the Device\n",
        "\n",
        "Currently, [`01-get-device-properties.cu`](../edit/04-device-properties/01-get-device-properties.cu) contains many unassigned variables, and will print gibberish information intended to describe details about the currently active GPU.\n",
        "\n",
        "Build out [`01-get-device-properties.cu`](../edit/04-device-properties/01-get-device-properties.cu) to print the actual values for the desired device properties indicated in the source code. In order to support your work, and as an introduction to them, use the [CUDA Runtime Docs](http://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html) to help identify the relevant properties in the device props struct. Refer to [the solution](../edit/04-device-properties/solutions/01-get-device-properties-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir  04-device-properties"
      ],
      "metadata": {
        "id": "8RsaTZOBnMIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 04-device-properties/01-get-device-properties.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Assign values to these variables so that the output string below prints the\n",
        "   * requested properties of the currently active GPU.\n",
        "   */\n",
        "\n",
        "\n",
        "\n",
        "int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "  /*\n",
        "   * `props` now contains several properties about the current device.\n",
        "   */\n",
        "\n",
        "  int computeCapabilityMajor = props.major;\n",
        "  int computeCapabilityMinor = props.minor;\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\nCompute Capability Major: %d\\nCompute Capability Minor: %d\\nWarp Size: %d\\n\", deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ig0pT2HnSoh",
        "outputId": "6a111229-d15a-40e8-f37c-c1727ff1c17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 04-device-properties/01-get-device-properties.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zg-8uhBeMZf",
        "outputId": "65879a49-9fa0-4114-fd17-d3c2f832b702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o get-device-properties 04-device-properties/01-get-device-properties.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uR8QjyNeMZf"
      },
      "source": [
        "### Exercise: Optimize Vector Add with Grids Sized to Number of SMs\n",
        "\n",
        "Utilize your ability to query the device for its number of SMs to refactor the `addVectorsInto` kernel you have been working on inside [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) so that it launches with a grid containing a number of blocks that is a multiple of the number of SMs on the device.\n",
        "\n",
        "Depending on other specific details in the code you have written, this refactor may or may not improve, or significantly change, the performance of your kernel. Therefore, as always, be sure to use `nsys profile` so that you can quantitatively evaluate performance changes. Record the results with the rest of your findings thus far, based on the profiling output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  printf(\"%d \\n\",N);\n",
        "  //exit(0);\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nsys should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  //-----------------\n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "  int computeCapabilityMajor = props.major;\n",
        "  int computeCapabilityMinor = props.minor;\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\nCompute Capability Major: %d\\nCompute Capability Minor: %d\\nWarp Size: %d\\n\", deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);\n",
        "\n",
        "  //----------\n",
        "  threadsPerBlock = 1024;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "  printf(\"Minimum Blocks Required: %zu\\n\", numberOfBlocks);\n",
        "\n",
        "  printf(\"threadsPerBlock = %zd    numberOfBlocks =%zd  novo = %zd \\n\",threadsPerBlock,numberOfBlocks,\n",
        "  ((numberOfBlocks + props.multiProcessorCount - 1) / props.multiProcessorCount)*props.multiProcessorCount);\n",
        "\n",
        "  numberOfBlocks = ((numberOfBlocks + props.multiProcessorCount - 1) /  props.multiProcessorCount) * props.multiProcessorCount;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  printf(\"Threads Per Block: %zu\\n\", threadsPerBlock);\n",
        "  printf(\"Launching with a Grid of %zu Blocks (a multiple of %d SMs)\\n\", numberOfBlocks, multiProcessorCount);\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTfckofpGi2",
        "outputId": "aecb50a4-afad-4bc2-a707-3cec6fafab2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp1wP4YseMZf",
        "outputId": "3345eca1-d839-4239-b893-f32d54d42c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33554432 \n",
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n",
            "Minimum Blocks Required: 32768\n",
            "threadsPerBlock = 1024    numberOfBlocks =32768  novo = 32800 \n",
            "Threads Per Block: 1024\n",
            "Launching with a Grid of 32800 Blocks (a multiple of 40 SMs)\n",
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 -o sm-optimized-vector-add 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3jst0r7eMZf",
        "outputId": "1fa3317a-9dee-41bf-d3a2-02f7660cff52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33554432 \n",
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n",
            "Minimum Blocks Required: 32768\n",
            "threadsPerBlock = 1024    numberOfBlocks =32768  novo = 32800 \n",
            "Threads Per Block: 1024\n",
            "Launching with a Grid of 32800 Blocks (a multiple of 40 SMs)\n",
            "Success! All values calculated correctly.\n",
            "Generating '/tmp/nsys-report-326a.qdstrm'\n",
            "[1/8] [========================100%] report1.nsys-rep\n",
            "[2/8] [========================100%] report1.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)    Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  ---------  -----------  ------------  ----------------------\n",
            "     89.7    1,663,940,367         73  22,793,703.7  10,073,856.0      1,613  337,746,074  46,328,704.6  poll                  \n",
            "      8.5      157,317,134        557     282,436.5      11,366.0        410  105,758,794   4,529,553.9  ioctl                 \n",
            "      1.2       21,825,456         24     909,394.0       9,387.0      2,158    8,683,696   2,447,171.1  mmap                  \n",
            "      0.2        4,318,215          1   4,318,215.0   4,318,215.0  4,318,215    4,318,215           0.0  pthread_cond_wait     \n",
            "      0.2        3,054,110         64      47,720.5         556.0        197    3,018,654     377,261.5  fcntl                 \n",
            "      0.1        1,810,877         31      58,415.4      12,483.0      9,273    1,086,932     192,066.3  mmap64                \n",
            "      0.0          657,044         10      65,704.4      51,882.0     24,492      227,300      57,993.8  sem_timedwait         \n",
            "      0.0          379,344         49       7,741.7       7,401.0      1,931       14,929       2,494.5  open64                \n",
            "      0.0          238,517         40       5,962.9       3,514.5      2,067       24,954       5,442.2  fopen                 \n",
            "      0.0          138,370         11      12,579.1       7,388.0      3,396       58,456      15,793.0  munmap                \n",
            "      0.0           99,960          2      49,980.0      49,980.0     47,407       52,553       3,638.8  pthread_create        \n",
            "      0.0           65,948         12       5,495.7       5,264.5      1,695        8,509       1,861.5  write                 \n",
            "      0.0           59,912         33       1,815.5       1,361.0        850        5,825       1,222.7  fclose                \n",
            "      0.0           38,222          6       6,370.3       5,287.5      1,504       14,502       4,762.3  open                  \n",
            "      0.0           37,026         19       1,948.7          47.0         44       36,110       8,272.5  fgets                 \n",
            "      0.0           22,950         15       1,530.0       1,348.0        807        4,056         820.1  read                  \n",
            "      0.0           21,224          2      10,612.0      10,612.0      7,267       13,957       4,730.5  socket                \n",
            "      0.0           18,098          3       6,032.7       5,992.0      4,369        7,737       1,684.4  pipe2                 \n",
            "      0.0           13,670          1      13,670.0      13,670.0     13,670       13,670           0.0  connect               \n",
            "      0.0           11,175          2       5,587.5       5,587.5      2,131        9,044       4,888.2  pthread_cond_broadcast\n",
            "      0.0            7,037          2       3,518.5       3,518.5      3,174        3,863         487.2  fwrite                \n",
            "      0.0            2,865          8         358.1         334.0        259          478          74.5  dup                   \n",
            "      0.0            1,597          1       1,597.0       1,597.0      1,597        1,597           0.0  bind                  \n",
            "      0.0              901          1         901.0         901.0        901          901           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)     StdDev (ns)                 Name               \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -------------  ---------------------------------\n",
            "     62.3      204,272,062          3   68,090,687.3       57,032.0       22,001  204,193,029  117,868,086.7  cudaMallocManaged                \n",
            "     30.9      101,443,456          1  101,443,456.0  101,443,456.0  101,443,456  101,443,456            0.0  cudaDeviceSynchronize            \n",
            "      6.7       21,817,379          3    7,272,459.7    6,544,159.0    6,484,137    8,789,083    1,313,777.2  cudaFree                         \n",
            "      0.1          226,430          1      226,430.0      226,430.0      226,430      226,430            0.0  cudaLaunchKernel                 \n",
            "      0.1          201,892          1      201,892.0      201,892.0      201,892      201,892            0.0  cudaGetDeviceProperties_v2_v12000\n",
            "      0.0            1,616          1        1,616.0        1,616.0        1,616        1,616            0.0  cuModuleGetLoadingMode           \n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ----------------------------------------------\n",
            "    100.0      101,429,392          1  101,429,392.0  101,429,392.0  101,429,392  101,429,392          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "     81.8       52,128,458  7,528   6,924.6   3,070.0     2,495    86,912     13,096.1  [CUDA memcpy Unified Host-to-Device]\n",
            "     18.2       11,608,989    768  15,115.9   4,399.5     2,015    81,343     22,804.1  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    402.653  7,528     0.053     0.008     0.004     0.983        0.161  [CUDA memcpy Unified Host-to-Device]\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report1.nsys-rep\n",
            "    /content/report1.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./sm-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4cRYYsCeMZg"
      },
      "source": [
        "---\n",
        "## Unified Memory Details\n",
        "\n",
        "You have been allocating memory intended for use either by host or device code with `cudaMallocManaged` and up until now have enjoyed the benefits of this method - automatic memory migration, ease of programming - without diving into the details of how the **Unified Memory** (**UM**) allocated by `cudaMallocManaged` actual works.\n",
        "\n",
        "`nsys profile` provides details about UM management in accelerated applications, and using this information, in conjunction with a more-detailed understanding of how UM works, provides additional opportunities to optimize accelerated applications.\n",
        "\n",
        "The following slides present upcoming material visually, at a high level. Click through the slides before moving on to more detailed coverage of their topics in following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "BeKv7emieMZg",
        "outputId": "18fd838e-0135-4819-e8b3-671c54a89fa4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task2/NVPROF_UM_2.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%HTML\n",
        "\n",
        "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task2/NVPROF_UM_2.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19m6wShmeMZg"
      },
      "source": [
        "### Unified Memory Migration\n",
        "\n",
        "When UM is allocated, the memory is not resident yet on either the host or the device. When either the host or device attempts to access the memory, a [page fault](https://en.wikipedia.org/wiki/Page_fault) will occur, at which point the host or device will migrate the needed data in batches. Similarly, at any point when the CPU, or any GPU in the accelerated system, attempts to access memory not yet resident on it, page faults will occur and trigger its migration.\n",
        "\n",
        "The ability to page fault and migrate memory on demand is tremendously helpful for ease of development in your accelerated applications. Additionally, when working with data that exhibits sparse access patterns, for example when it is impossible to know which data will be required to be worked on until the application actually runs, and for scenarios when data might be accessed by multiple GPU devices in an accelerated system with multiple GPUs, on-demand memory migration is remarkably beneficial.\n",
        "\n",
        "There are times - for example when data needs are known prior to runtime, and large contiguous blocks of memory are required - when the overhead of page faulting and migrating data on demand incurs an overhead cost that would be better avoided.\n",
        "\n",
        "Much of the remainder of this lab will be dedicated to understanding on-demand migration, and how to identify it in the profiler's output. With this knowledge you will be able to reduce the overhead of it in scenarios when it would be beneficial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3XAvkQCeMZg"
      },
      "source": [
        "### Exercise: Explore UM Migration and Page Faulting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlmaeG9YeMZg"
      },
      "source": [
        "`nsys profile` provides output describing UM behavior for the profiled application. In this exercise, you will make several modifications to a simple application, and make use of `nsys profile` after each change, to explore how UM data migration behaves.\n",
        "\n",
        "[`01-page-faults.cu`](../edit/06-unified-memory-page-faults/01-page-faults.cu) contains a `hostFunction` and a `gpuKernel`, both which could be used to initialize the elements of a `2<<24` element vector with the number `1`. Currently neither the host function nor GPU kernel are being used.\n",
        "\n",
        "For each of the 4 questions below, given what you have just learned about UM behavior, first hypothesize about what kind of page faulting should happen, then, edit [`01-page-faults.cu`](../edit/06-unified-memory-page-faults/01-page-faults.cu) to create a scenario, by using one or both of the 2 provided functions in the code bases, that will allow you to test your hypothesis.\n",
        "\n",
        "In order to test your hypotheses, compile and profile your code using the code execution cells below. Be sure to record your hypotheses, as well as the results, obtained from `nsys profile --stats=true` output. In the output of `nsys profile --stats=true` you should be looking for the following:\n",
        "\n",
        "- Is there a _CUDA Memory Operation Statistics_ section in the output?\n",
        "- If so, does it indicate host to device (HtoD) or device to host (DtoH) migrations?\n",
        "- When there are migrations, what does the output say about how many _Operations_ there were? If you see many small memory migration operations, this is a sign that on-demand page faulting is occurring, with small memory migrations occurring each time there is a page fault in the requested location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56-1tiMgeMZg"
      },
      "source": [
        "Here are the scenarios for you to explore, along with solutions for them if you get stuck:\n",
        "\n",
        "- Is there evidence of memory migration and/or page faulting when unified memory is accessed only by the CPU? ([solution](../edit/06-unified-memory-page-faults/solutions/01-page-faults-solution-cpu-only.cu))\n",
        "- Is there evidence of memory migration and/or page faulting when unified memory is accessed only by the GPU? ([solution](../edit/06-unified-memory-page-faults/solutions/02-page-faults-solution-gpu-only.cu))\n",
        "- Is there evidence of memory migration and/or page faulting when unified memory is accessed first by the CPU then the GPU? ([solution](../edit/06-unified-memory-page-faults/solutions/03-page-faults-solution-cpu-then-gpu.cu))\n",
        "- Is there evidence of memory migration and/or page faulting when unified memory is accessed first by the GPU then the CPU? ([solution](../edit/06-unified-memory-page-faults/solutions/04-page-faults-solution-gpu-then-cpu.cu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjfmun5zeMZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af578d0-b59d-4e77-c41f-ff1d4fc43c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[K06-unified-memory-page-faults/01-page-faults.cu: No such file or directory\n",
            "compilation terminated.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o page-faults 06-unified-memory-page-faults/01-page-faults.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWTGCkqeMZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f4ba30-e68b-4264-aec6-b080f4d78950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nsys: command not found\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./page-faults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7D9gf5YeMZg"
      },
      "source": [
        "### Exercise: Revisit UM Behavior for Vector Add Program\n",
        "\n",
        "Returning to the [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) program you have been working on throughout this lab, review the code bases in its current state, and hypothesize about what kinds of memory migrations and/or page faults you expect to occur. Look at the profiling output for your last refactor (either by scrolling up to find the output or by executing the code execution cell just below), observing the _CUDA Memory Operation Statistics_ section of the profiler output. Can you explain the kinds of migrations and the number of their operations based on the contents of the code base?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWHhOyjoeMZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def6b77b-a4fc-4b01-a9bb-a30329970dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nsys: command not found\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./sm-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv51GT8GeMZh"
      },
      "source": [
        "### Exercise: Initialize Vector in Kernel\n",
        "\n",
        "When `nsys profile` gives the amount of time that a kernel takes to execute, the host-to-device page faults and data migrations that occur during this kernel's execution are included in the displayed execution time.\n",
        "\n",
        "With this in mind, refactor the `initWith` host function in your [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) program to instead be a CUDA kernel, initializing the allocated vector in parallel on the GPU. After successfully compiling and running the refactored application, but before profiling it, hypothesize about the following:\n",
        "\n",
        "- How do you expect the refactor to affect UM memory migration behavior?\n",
        "- How do you expect the refactor to affect the reported run time of `addVectorsInto`?\n",
        "\n",
        "Once again, record the results. Refer to [the solution](../edit/07-init-in-kernel/solutions/01-vector-add-init-in-kernel-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "  int computeCapabilityMajor = props.major;\n",
        "  int computeCapabilityMinor = props.minor;\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\nCompute Capability Major: %d\\nCompute Capability Minor: %d\\nWarp Size: %d\\n\", deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);\n",
        "\n",
        "  threadsPerBlock = 1024;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  numberOfBlocks = ((numberOfBlocks + props.multiProcessorCount - 1) /  props.multiProcessorCount) * props.multiProcessorCount;\n",
        "\n",
        "  checkCuda( cudaMallocManaged(&a, size) );\n",
        "  checkCuda( cudaMallocManaged(&b, size) );\n",
        "  checkCuda( cudaMallocManaged(&c, size) );\n",
        "\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(3, a, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(4, b, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(0, c, N);\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  checkCuda( cudaFree(a) );\n",
        "  checkCuda( cudaFree(b) );\n",
        "  checkCuda( cudaFree(c) );\n",
        "}\n"
      ],
      "metadata": {
        "id": "vvEJYxV94xwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04f868f-8cd3-4b81-b36b-809dd86122a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pJvT692seMZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e86f72-3f5d-4f66-e8ff-83241d2edf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 -o initialize-in-kernel 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yQVW6i4weMZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cf1dcd-8fd9-4c8e-9197-c00b3120d98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n",
            "Generating '/tmp/nsys-report-9d58.qdstrm'\n",
            "[1/8] [========================100%] report2.nsys-rep\n",
            "[2/8] [========================100%] report2.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report2.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     90.0    1,026,595,483         41  25,038,914.2  10,066,362.0     1,755  459,329,155  72,772,110.1  poll                  \n",
            "      7.0       79,354,718        557     142,468.1      15,241.0       656   22,062,112   1,159,834.6  ioctl                 \n",
            "      2.1       23,470,937         24     977,955.7      11,039.5     3,126   10,395,165   2,686,968.8  mmap                  \n",
            "      0.6        6,648,276          2   3,324,138.0   3,324,138.0     2,229    6,646,047   4,697,888.8  pthread_cond_broadcast\n",
            "      0.3        2,958,387         31      95,431.8      18,540.0    13,182    1,910,071     337,951.4  mmap64                \n",
            "      0.0          433,096         49       8,838.7       8,328.0     2,940       17,913       2,965.4  open64                \n",
            "      0.0          270,724         12      22,560.3      26,181.0       961       42,155      12,890.1  write                 \n",
            "      0.0          259,908         40       6,497.7       4,075.0     1,689       32,553       5,939.9  fopen                 \n",
            "      0.0          103,397          2      51,698.5      51,698.5    45,657       57,740       8,544.0  pthread_create        \n",
            "      0.0          101,063         11       9,187.5       8,960.0     5,577       15,067       2,765.1  munmap                \n",
            "      0.0           96,098          1      96,098.0      96,098.0    96,098       96,098           0.0  pthread_cond_wait     \n",
            "      0.0           86,094         33       2,608.9       1,771.0     1,339       16,641       2,838.7  fclose                \n",
            "      0.0           52,533         19       2,764.9          75.0        67       51,132      11,712.6  fgets                 \n",
            "      0.0           41,163         64         643.2         700.0       274        1,148         196.6  fcntl                 \n",
            "      0.0           38,108          6       6,351.3       6,592.5     2,509        9,878       2,688.6  open                  \n",
            "      0.0           35,132         15       2,342.1       1,039.0       472       18,858       4,623.0  read                  \n",
            "      0.0           21,251          3       7,083.7       7,990.0     5,025        8,236       1,787.1  pipe2                 \n",
            "      0.0           20,067          2      10,033.5      10,033.5     8,097       11,970       2,738.6  socket                \n",
            "      0.0           10,623          1      10,623.0      10,623.0    10,623       10,623           0.0  connect               \n",
            "      0.0            7,149          2       3,574.5       3,574.5     3,067        4,082         717.7  fwrite                \n",
            "      0.0            3,486          8         435.8         441.5       335          621         100.3  dup                   \n",
            "      0.0            1,795          1       1,795.0       1,795.0     1,795        1,795           0.0  bind                  \n",
            "      0.0            1,154          1       1,154.0       1,154.0     1,154        1,154           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)    Max (ns)    StdDev (ns)                 Name               \n",
            " --------  ---------------  ---------  ------------  ------------  ---------  -----------  ------------  ---------------------------------\n",
            "     49.7      132,363,362          3  44,121,120.7      69,287.0     35,741  132,258,334  76,329,067.6  cudaMallocManaged                \n",
            "     41.3      109,879,874          2  54,939,937.0  54,939,937.0  2,237,555  107,642,319  74,532,423.4  cudaDeviceSynchronize            \n",
            "      8.8       23,377,757          3   7,792,585.7   6,504,034.0  6,414,534   10,459,189   2,309,779.8  cudaFree                         \n",
            "      0.1          303,933          4      75,983.3      53,784.5      5,990      190,374      87,782.3  cudaLaunchKernel                 \n",
            "      0.1          136,642          1     136,642.0     136,642.0    136,642      136,642           0.0  cudaGetDeviceProperties_v2_v12000\n",
            "      0.0            1,528          1       1,528.0       1,528.0      1,528        1,528           0.0  cuModuleGetLoadingMode           \n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)      Med (ns)     Min (ns)    Max (ns)   StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  ------------  ------------  ----------  ----------  -----------  ----------------------------------------------\n",
            "     98.0      107,640,461          3  35,880,153.7  36,017,815.0  33,947,269  37,675,377  1,867,862.5  initWith(float, float *, int)                 \n",
            "      2.0        2,242,414          1   2,242,414.0   2,242,414.0   2,242,414   2,242,414          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    100.0       11,633,364    768  15,147.6   4,399.5     1,983    81,566     22,810.4  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report2.nsys-rep\n",
            "    /content/report2.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./initialize-in-kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRNVvIKleMZh"
      },
      "source": [
        "---\n",
        "## Asynchronous Memory Prefetching\n",
        "\n",
        "A powerful technique to reduce the overhead of page faulting and on-demand memory migrations, both in host-to-device and device-to-host memory transfers, is called **asynchronous memory prefetching**. Using this technique allows programmers to asynchronously migrate unified memory (UM) to any CPU or GPU device in the system, in the background, prior to its use by application code. By doing this, GPU kernels and CPU function performance can be increased on account of reduced page fault and on-demand data migration overhead.\n",
        "\n",
        "Prefetching also tends to migrate data in larger chunks, and therefore fewer trips, than on-demand migration. This makes it an excellent fit when data access needs are known before runtime, and when data access patterns are not sparse.\n",
        "\n",
        "CUDA Makes asynchronously prefetching managed memory to either a GPU device or the CPU easy with its `cudaMemPrefetchAsync` function. Here is an example of using it to both prefetch data to the currently active GPU device, and then, to the CPU:\n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n",
        "\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n",
        "                                                                  // built-in CUDA variable.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItmiIqReMZh"
      },
      "source": [
        "### Exercise: Prefetch Memory\n",
        "\n",
        "At this point in the lab, your [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) program should not only be launching a CUDA kernel to add 2 vectors into a third solution vector, all which are allocated with `cudaMallocManaged`, but should also be initializing each of the 3 vectors in parallel in a CUDA kernel. If for some reason, your application does not do any of the above, please refer to the following [reference application](../edit/07-init-in-kernel/solutions/01-vector-add-init-in-kernel-solution.cu), and update your own code bases to reflect its current functionality.\n",
        "\n",
        "Conduct 3 experiments using `cudaMemPrefetchAsync` inside of your [01-vector-add.cu](../edit/01-vector-add/01-vector-add.cu) application to understand its impact on page-faulting and memory migration.\n",
        "\n",
        "- What happens when you prefetch one of the initialized vectors to the device?\n",
        "- What happens when you prefetch two of the initialized vectors to the device?\n",
        "- What happens when you prefetch all three of the initialized vectors to the device?\n",
        "\n",
        "Hypothesize about UM behavior, page faulting specifically, as well as the impact on the reported run time of the initialization kernel, before each experiment, and then verify by running `nsys profile`. Refer to [the solution](../edit/08-prefetch/solutions/01-vector-add-prefetch-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  int deviceId;\n",
        "  checkCuda( cudaGetDevice(&deviceId) );\n",
        "  cudaDeviceProp props;\n",
        "  checkCuda( cudaGetDeviceProperties(&props, deviceId) );\n",
        "\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\n\", deviceId, props.multiProcessorCount);\n",
        "\n",
        "  threadsPerBlock = 1024;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  numberOfBlocks = ((numberOfBlocks + props.multiProcessorCount - 1) /  props.multiProcessorCount) * props.multiProcessorCount;\n",
        "\n",
        "  checkCuda( cudaMallocManaged(&a, size) );\n",
        "  checkCuda( cudaMallocManaged(&b, size) );\n",
        "  checkCuda( cudaMallocManaged(&c, size) );\n",
        "\n",
        "  checkCuda( cudaMemPrefetchAsync(a, size, deviceId, 0) );\n",
        "  checkCuda( cudaMemPrefetchAsync(b, size, deviceId, 0) );\n",
        "  checkCuda( cudaMemPrefetchAsync(c, size, deviceId, 0) );\n",
        "\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(3, a, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(4, b, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(0, c, N);\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  //checkCuda( cudaMemPrefetchAsync(c, size, cudaCpuDeviceId, 0) );\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  checkCuda( cudaFree(a) );\n",
        "  checkCuda( cudaFree(b) );\n",
        "  checkCuda( cudaFree(c) );\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDBD4BLu9EqD",
        "outputId": "92f2bad5-37b7-47aa-85d4-df3c863ab050"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hCYc6DFdeMZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9b5c61-518d-43cb-c18f-b8a2c25b7ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 -o prefetch-to-gpu 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1jJRj0vXeMZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e143c68-cfa0-4bb0-998b-90e2578d8a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Generating '/tmp/nsys-report-8ce7.qdstrm'\n",
            "[1/8] [========================100%] report2.nsys-rep\n",
            "[2/8] [========================100%] report2.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report2.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     88.0      698,378,820         32  21,824,338.1  10,076,266.5     2,513  334,772,863  59,428,660.0  poll                  \n",
            "      8.1       64,226,683        560     114,690.5      12,706.5       544   19,246,166     895,370.3  ioctl                 \n",
            "      2.2       17,204,124         24     716,838.5      11,434.0     2,398   15,318,077   3,117,381.6  mmap                  \n",
            "      1.1        8,487,698          3   2,829,232.7       2,315.0     1,912    8,483,471   4,896,714.0  pthread_cond_broadcast\n",
            "      0.3        2,000,278         31      64,525.1      17,874.0    10,022    1,114,145     196,177.5  mmap64                \n",
            "      0.1          700,042          2     350,021.0     350,021.0   150,584      549,458     282,046.5  sem_wait              \n",
            "      0.1          614,175          6     102,362.5      58,367.5    23,842      369,190     132,428.8  sem_timedwait         \n",
            "      0.1          435,744         49       8,892.7       8,288.0     2,207       18,282       3,368.2  open64                \n",
            "      0.0          246,559         40       6,164.0       3,550.5     1,834       29,903       6,463.5  fopen                 \n",
            "      0.0          192,505          3      64,168.3      67,035.0    53,222       72,248       9,831.6  pthread_create        \n",
            "      0.0          191,174         13      14,705.7       7,142.0     1,563       37,087      13,995.4  write                 \n",
            "      0.0          122,445         11      11,131.4       8,177.0     3,984       31,752       7,833.1  munmap                \n",
            "      0.0          102,784          1     102,784.0     102,784.0   102,784      102,784           0.0  pthread_cond_wait     \n",
            "      0.0           61,940         33       1,877.0       1,526.0       890        7,204       1,360.2  fclose                \n",
            "      0.0           54,905         19       2,889.7          62.0        52       53,712      12,307.2  fgets                 \n",
            "      0.0           47,296          6       7,882.7       7,801.0     2,525       14,246       4,782.2  open                  \n",
            "      0.0           39,347         64         614.8         592.5       205        1,836         279.9  fcntl                 \n",
            "      0.0           24,200         16       1,512.5       1,179.0       771        3,885         804.5  read                  \n",
            "      0.0           21,690          3       7,230.0       7,541.0     5,242        8,907       1,852.2  pipe2                 \n",
            "      0.0           19,676          2       9,838.0       9,838.0     6,860       12,816       4,211.5  socket                \n",
            "      0.0           10,641          1      10,641.0      10,641.0    10,641       10,641           0.0  connect               \n",
            "      0.0            7,086          2       3,543.0       3,543.0     3,225        3,861         449.7  fwrite                \n",
            "      0.0            3,225          8         403.1         426.0       271          517         105.8  dup                   \n",
            "      0.0            1,870          1       1,870.0       1,870.0     1,870        1,870           0.0  bind                  \n",
            "      0.0            1,251          1       1,251.0       1,251.0     1,251        1,251           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)    Max (ns)    StdDev (ns)                 Name               \n",
            " --------  ---------------  ---------  ------------  -----------  ---------  -----------  ------------  ---------------------------------\n",
            "     80.3      108,152,745          3  36,050,915.0     95,343.0     34,077  108,023,325  62,329,943.0  cudaMallocManaged                \n",
            "     12.7       17,141,576          3   5,713,858.7    909,066.0    825,107   15,407,403   8,394,960.6  cudaFree                         \n",
            "      4.8        6,457,390          1   6,457,390.0  6,457,390.0  6,457,390    6,457,390           0.0  cudaDeviceSynchronize            \n",
            "      1.2        1,588,694          4     397,173.5     12,089.0      4,337    1,560,179     775,357.4  cudaLaunchKernel                 \n",
            "      0.9        1,258,339          3     419,446.3    593,111.0     14,825      650,403     351,581.3  cudaMemPrefetchAsync             \n",
            "      0.1          113,250          1     113,250.0    113,250.0    113,250      113,250           0.0  cudaGetDeviceProperties_v2_v12000\n",
            "      0.0            1,451          1       1,451.0      1,451.0      1,451        1,451           0.0  cuModuleGetLoadingMode           \n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------------------------------------------\n",
            "     65.4        4,233,892          3  1,411,297.3  1,411,233.0  1,411,169  1,411,490        169.9  initWith(float, float *, int)                 \n",
            "     34.6        2,242,607          1  2,242,607.0  2,242,607.0  2,242,607  2,242,607          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    100.0       11,640,579    768  15,157.0   4,383.5     1,919    88,574     22,951.6  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report2.nsys-rep\n",
            "    /content/report2.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./prefetch-to-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flvQYLGbeMZh"
      },
      "source": [
        "### Exercise: Prefetch Memory Back to the CPU\n",
        "\n",
        "Add additional prefetching back to the CPU for the function that verifies the correctness of the `addVectorInto` kernel. Again, hypothesize about the impact on UM before profiling in `nsys` to confirm. Refer to [the solution](../edit/08-prefetch/solutions/02-vector-add-prefetch-solution-cpu-also.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 01-vector-add/01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "inline cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "  return result;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void checkElementsAre(float target, float *array, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(array[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\", i, array[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  int deviceId;\n",
        "  checkCuda( cudaGetDevice(&deviceId) );\n",
        "  cudaDeviceProp props;\n",
        "  checkCuda( cudaGetDeviceProperties(&props, deviceId) );\n",
        "\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\n\", deviceId, props.multiProcessorCount);\n",
        "\n",
        "  threadsPerBlock = 1024;\n",
        "  numberOfBlocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  numberOfBlocks = ((numberOfBlocks + props.multiProcessorCount - 1) /  props.multiProcessorCount) * props.multiProcessorCount;\n",
        "\n",
        "  checkCuda( cudaMallocManaged(&a, size) );\n",
        "  checkCuda( cudaMallocManaged(&b, size) );\n",
        "  checkCuda( cudaMallocManaged(&c, size) );\n",
        "\n",
        "  checkCuda( cudaMemPrefetchAsync(a, size, deviceId, 0) );\n",
        "  checkCuda( cudaMemPrefetchAsync(b, size, deviceId, 0) );\n",
        "  checkCuda( cudaMemPrefetchAsync(c, size, deviceId, 0) );\n",
        "\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(3, a, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(4, b, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(0, c, N);\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  checkCuda( cudaMemPrefetchAsync(c, size, cudaCpuDeviceId, 0) );\n",
        "\n",
        "  checkCuda( cudaGetLastError() );\n",
        "  checkCuda( cudaDeviceSynchronize() );\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  checkCuda( cudaFree(a) );\n",
        "  checkCuda( cudaFree(b) );\n",
        "  checkCuda( cudaFree(c) );\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25NKrjs1AzfE",
        "outputId": "bde1d55a-d27b-4fc5-e148-b0dee4995be2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 01-vector-add/01-vector-add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QjWBOI_WeMZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365eefce-c4b7-47ff-b4f5-589ef1276b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 -o prefetch-to-cpu 01-vector-add/01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QOHRGKnbeMZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66630e8a-f32e-4f87-c84e-c8a46a24c218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Generating '/tmp/nsys-report-c777.qdstrm'\n",
            "[1/8] [========================100%] report3.nsys-rep\n",
            "[2/8] [========================100%] report3.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report3.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     85.2      649,636,799         27  24,060,622.2  10,072,145.0     2,585  328,753,129  62,904,914.2  poll                  \n",
            "     10.9       82,805,625        561     147,603.6      13,250.0       574   18,302,230   1,102,760.0  ioctl                 \n",
            "      1.0        7,613,750          3   2,537,916.7       2,646.0     2,505    7,608,599   4,391,339.7  pthread_cond_broadcast\n",
            "      0.9        6,533,053         24     272,210.5      12,702.5     1,902    4,289,862     894,030.9  mmap                  \n",
            "      0.9        6,511,477          2   3,255,738.5   3,255,738.5   545,575    5,965,902   3,832,750.0  sem_wait              \n",
            "      0.7        5,041,127         49     102,880.1       7,612.0     2,253    4,628,022     659,925.4  open64                \n",
            "      0.3        2,008,680         31      64,796.1      14,333.0    10,200    1,110,657     195,710.7  mmap64                \n",
            "      0.1          923,393         10      92,339.3      61,362.5    25,358      424,445     117,774.5  sem_timedwait         \n",
            "      0.0          250,712         40       6,267.8       3,783.5     2,011       30,140       6,156.2  fopen                 \n",
            "      0.0          212,989         12      17,749.1       8,453.5     4,676      106,911      28,441.0  munmap                \n",
            "      0.0          193,747          3      64,582.3      73,122.0    45,810       74,815      16,279.3  pthread_create        \n",
            "      0.0          110,893          1     110,893.0     110,893.0   110,893      110,893           0.0  pthread_cond_wait     \n",
            "      0.0           86,384         13       6,644.9       6,127.0       959       18,970       4,163.9  write                 \n",
            "      0.0           60,199         33       1,824.2       1,283.0       894        6,649       1,216.8  fclose                \n",
            "      0.0           39,871          6       6,645.2       4,880.0     1,614       14,689       5,023.4  open                  \n",
            "      0.0           37,411         64         584.5         540.0       186        1,769         279.6  fcntl                 \n",
            "      0.0           37,353         19       1,965.9          46.0        44       36,424       8,344.4  fgets                 \n",
            "      0.0           27,030         16       1,689.4       1,526.5       842        3,961         763.8  read                  \n",
            "      0.0           19,139          3       6,379.7       6,750.0     3,525        8,864       2,688.7  pipe2                 \n",
            "      0.0           18,465          2       9,232.5       9,232.5     6,991       11,474       3,170.0  socket                \n",
            "      0.0           10,421          1      10,421.0      10,421.0    10,421       10,421           0.0  connect               \n",
            "      0.0            6,544          2       3,272.0       3,272.0     3,265        3,279           9.9  fwrite                \n",
            "      0.0            3,032          8         379.0         352.0       259          624         111.6  dup                   \n",
            "      0.0            1,993          1       1,993.0       1,993.0     1,993        1,993           0.0  bind                  \n",
            "      0.0            1,249          1       1,249.0       1,249.0     1,249        1,249           0.0  listen                \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)    StdDev (ns)                 Name               \n",
            " --------  ---------------  ---------  ------------  ------------  ----------  -----------  ------------  ---------------------------------\n",
            "     82.2      125,677,021          3  41,892,340.3      89,477.0      33,527  125,554,017  72,453,142.7  cudaMallocManaged                \n",
            "     11.8       18,068,119          1  18,068,119.0  18,068,119.0  18,068,119   18,068,119           0.0  cudaDeviceSynchronize            \n",
            "      4.3        6,512,031          3   2,170,677.0   1,090,646.0   1,067,493    4,353,892   1,890,755.1  cudaFree                         \n",
            "      1.5        2,358,697          4     589,674.3     591,197.0     522,299      654,004      61,746.4  cudaMemPrefetchAsync             \n",
            "      0.2          246,615          4      61,653.8      21,562.5       5,922      197,568      91,329.3  cudaLaunchKernel                 \n",
            "      0.1          108,389          1     108,389.0     108,389.0     108,389      108,389           0.0  cudaGetDeviceProperties_v2_v12000\n",
            "      0.0            1,180          1       1,180.0       1,180.0       1,180        1,180           0.0  cuModuleGetLoadingMode           \n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------------------------------------------\n",
            "     65.4        4,234,084          3  1,411,361.3  1,411,329.0  1,411,329  1,411,426         56.0  initWith(float, float *, int)                 \n",
            "     34.6        2,243,023          1  2,243,023.0  2,243,023.0  2,243,023  2,243,023          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
            " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ------------------------------------\n",
            "    100.0       10,317,023     64  161,203.5  160,668.0   160,477   169,532      1,824.6  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
            "    134.218     64     2.097     2.097     2.097     2.097        0.000  [CUDA memcpy Unified Device-to-Host]\n",
            "\n",
            "Generated:\n",
            "    /content/report3.nsys-rep\n",
            "    /content/report3.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./prefetch-to-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHHc4p1GeMZi"
      },
      "source": [
        "After this series of refactors to use asynchronous prefetching, you should see that there are fewer, but larger, memory transfers, and, that the kernel execution time is significantly decreased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJsd4NIYeMZi"
      },
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "At this point in the lab, you are able to:\n",
        "\n",
        "- Use the Nsight Systems command line tool (**nsys**) to profile accelerated application performance.\n",
        "- Leverage an understanding of **Streaming Multiprocessors** to optimize execution configurations.\n",
        "- Understand the behavior of **Unified Memory** with regard to page faulting and data migrations.\n",
        "- Use **asynchronous memory prefetching** to reduce page faults and data migrations for increased performance.\n",
        "- Employ an iterative development cycle to rapidly accelerate and deploy applications.\n",
        "\n",
        "In order to consolidate your learning, and reinforce your ability to iteratively accelerate, optimize, and deploy applications, please proceed to this lab's final exercise. After completing it, for those of you with time and interest, please proceed to the *Advanced Content* section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVVlyL1ReMZi"
      },
      "source": [
        "---\n",
        "## Final Exercise: Iteratively Optimize an Accelerated SAXPY Application\n",
        "\n",
        "A basic accelerated SAXPY (Single Precision a\\*x+b) application has been provided for you [here](../edit/09-saxpy/01-saxpy.cu). It currently contains a couple of bugs that you will need to find and fix before you can successfully compile, run, and then profile it with `nsys profile`.\n",
        "\n",
        "After fixing the bugs and profiling the application, record the runtime of the `saxpy` kernel and then work *iteratively* to optimize the application, using `nsys profile` after each iteration to notice the effects of the code changes on kernel performance and UM behavior.\n",
        "\n",
        "Utilize the techniques from this lab. To support your learning, utilize [effortful retrieval](http://sites.gsu.edu/scholarlyteaching/effortful-retrieval/) whenever possible, rather than rushing to look up the specifics of techniques from earlier in the lesson.\n",
        "\n",
        "Your end goal is to profile an accurate `saxpy` kernel, without modifying `N`, to run in under *200us*. Check out [the solution](../edit/09-saxpy/solutions/02-saxpy-solution.cu) if you get stuck, and feel free to compile and profile it if you wish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I38p82XveMZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a362fc6b-2942-4a5d-a17c-6b72913b87d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[K09-saxpy/01-saxpy.cu: No such file or directory\n",
            "compilation terminated.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o saxpy 09-saxpy/01-saxpy.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzm83WpHeMZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e78d4bf-20c8-4915-f81e-4d48258fb7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nsys: command not found\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./saxpy"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}